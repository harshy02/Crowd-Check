{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "social distancing detector.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "mount_file_id": "1xhUegkvbBLX4R5Ew2ZlewxmHU18tjnxH",
      "authorship_tag": "ABX9TyNUGFVp2liAYO3G/ztUUW/K"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "oqeuTx8LSzYC"
      },
      "source": [
        "#colab has CUDA 10.1\n",
        "#install dependencies:\n",
        "!pip install cython pyyaml==5.1 pycocotools>=2.0.1\n",
        "\n",
        "# install detectron2 for torch 1.6:\n",
        "!pip install detectron2 -f https://dl.fbaipublicfiles.com/detectron2/wheels/cu101/torch1.6/index.html"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MpExMy-JlR-E"
      },
      "source": [
        "# basic setupa:\n",
        "# Import and setup detectron2 logger\n",
        "import detectron2\n",
        "from detectron2.utils.logger import setup_logger\n",
        "setup_logger()\n",
        "\n",
        "# import required python libraries\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# import detectron2 utilities\n",
        "from detectron2 import model_zoo\n",
        "from detectron2.engine import DefaultPredictor\n",
        "from detectron2.data import MetadataCatalog\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2.utils.visualizer import Visualizer\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1-o-mfDjluxd"
      },
      "source": [
        "# Read a video\n",
        "# Save frames to a folder\n",
        "%%time\n",
        "!rm -r frames/*       # remove\n",
        "!mkdir frames/        # make directory\n",
        "\n",
        "# path to video\n",
        "video = \"/content/drive/My Drive/Crowd Check/street.mp4\"\n",
        "\n",
        "#capture video\n",
        "cap = cv2.VideoCapture(video)\n",
        "cnt = 0\n",
        "\n",
        "# Check if video file is opened successfully\n",
        "if (cap.isOpened()== False): \n",
        "  print(\"Error opening video stream or file\")\n",
        "\n",
        "ret, first_frame = cap.read()\n",
        "\n",
        "# Read until video is finished\n",
        "while(cap.isOpened()):\n",
        "    \n",
        "  # Capture video frame-by-frame\n",
        "  ret, frame = cap.read()\n",
        "     \n",
        "  if ret == True:\n",
        "\n",
        "    # Save each frame to a folder        \n",
        "    cv2.imwrite('frames/' + str(cnt) + '.png', frame)       # Save frames in .png\n",
        "    cnt += 1\n",
        "    if(cnt==750):\n",
        "      break\n",
        "\n",
        "  # Break loop\n",
        "  else: \n",
        "    break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X9drY7o_lzPL"
      },
      "source": [
        "# Check frame rate of input video\n",
        "FPS = cap.get(cv2.CAP_PROP_FPS)\n",
        "print(FPS)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IU_YSRxwl6Ac"
      },
      "source": [
        "# create a detectron2 config and a detectron2 DefaultPredictor to run inference \n",
        "cfg = get_cfg()\n",
        "\n",
        "# add project-specific config\n",
        "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/faster_rcnn_R_50_C4_3x.yaml\"))\n",
        "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.9  # set threshold for this model\n",
        "\n",
        "# Find a pre-trained model from detectron2's model zoo\n",
        "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-Detection/faster_rcnn_R_50_C4_3x.yaml\")\n",
        "predictor = DefaultPredictor(cfg)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xFAmV2RdnL1b"
      },
      "source": [
        "#read an image in frames folder\n",
        "img = cv2.imread(\"/content/frames/100.png\")\n",
        "\n",
        "#pass into the model for predictions\n",
        "outputs = predictor(img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "unwOhLpEosc-"
      },
      "source": [
        "# Use `Visualizer` to draw the predictions on the image.\n",
        "v = Visualizer(img[:, :, ::-1], MetadataCatalog.get(cfg.DATASETS.TRAIN[0]), scale = 1.2)\n",
        "v = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
        "# show predicted output\n",
        "cv2_imshow(v.get_image()[:, :, ::-1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4DjTHmMsO_pI"
      },
      "source": [
        "# Outputs\n",
        "# Objects present in image\n",
        "classes = outputs['instances'].pred_classes.cpu().numpy()\n",
        "print(classes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z9PiIRoros65"
      },
      "source": [
        "# bounding boxed of an object\n",
        "bbox = outputs['instances'].pred_boxes.tensor.cpu().numpy()\n",
        "print(bbox)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pnQxl-ZbPFWt"
      },
      "source": [
        "# identify only required classes and bounding boxes\n",
        "# identity only persons \n",
        "ind = np.where(classes==0)[0]\n",
        "\n",
        "# identify bounding box of only persons\n",
        "person = bbox[ind]\n",
        "\n",
        "# calculate total no. of persons\n",
        "num = len(person)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F-ZVzT7MPJk-"
      },
      "source": [
        "# format of bounding box\n",
        "x1, y1, x2, y2 = person[0]\n",
        "print(x1, y1, x2, y2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rCrR4bfoPMSO"
      },
      "source": [
        "# Draw bounding box for one person\n",
        "img = cv2.imread('frames/30.png')\n",
        "_ = cv2.rectangle(img, (x1, y1), (x2, y2), (255, 0, 0), 2)\n",
        "\n",
        "plt.figure(figsize = (20,10))\n",
        "# show plot\n",
        "plt.imshow(img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f6k2zPecPPxR"
      },
      "source": [
        "# set paramenters for computing the distance between two people\n",
        "# compute center \n",
        "#  Using bottom center of a rectangle for representing each person\n",
        "x_center = int((x1+x2)/2)\n",
        "y_center = int(y2)\n",
        "\n",
        "center = (x_center, y_center)\n",
        "\n",
        "_ = cv2.circle(img, center, 5, (255, 0, 0), -1)\n",
        "plt.figure(figsize=(20,10))\n",
        "plt.imshow(img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b1_UZszAPaPH"
      },
      "source": [
        "#define a function which return the bottom center of every bbox\n",
        "def mid_point(img, person, idx):\n",
        "  #get the coordinates\n",
        "  x1,y1,x2,y2 = person[idx]\n",
        "  _ = cv2.rectangle(img, (x1, y1), (x2, y2), (0,0,255), 2)\n",
        "  \n",
        "  #compute bottom center of bbox\n",
        "  x_mid = int((x1+x2)/2)\n",
        "  y_mid = int(y2)\n",
        "  mid = (x_mid,y_mid)\n",
        "  \n",
        "  _ = cv2.circle(img, mid, 5, (0, 0, 255), -1)\n",
        "  cv2.putText(img, str(idx), mid, cv2.FONT_HERSHEY_SIMPLEX,1, (255, 255, 255), 2, cv2.LINE_AA)\n",
        "  \n",
        "  return mid"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qPJ33p6KPe-t"
      },
      "source": [
        "# Compute bottom center for every bounding box and draw the points on the image\n",
        "# call the function\n",
        "midpoints = [mid_point(img,person,i) for i in range(len(person))]\n",
        "\n",
        "# visualize image\n",
        "plt.figure(figsize=(20, 10))\n",
        "# show image\n",
        "plt.imshow(img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BS23XdiOPhxr"
      },
      "source": [
        "# define function to compute the Euclidean distance between every two points in image\n",
        "%%time\n",
        "from scipy.spatial import distance\n",
        "def compute_distance(midpoints,num):\n",
        "  dist = np.zeros((num,num))\n",
        "  for i in range(num):\n",
        "    for j in range(i+1,num):\n",
        "      if i!=j:\n",
        "        dst = distance.euclidean(midpoints[i], midpoints[j])\n",
        "        dist[i][j] = dst\n",
        "  return dist"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BI7tJl1BPpFQ"
      },
      "source": [
        "# Compute distance between every pair of points\n",
        "dist = compute_distance(midpoints, num)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kfQh4YbePr0N"
      },
      "source": [
        "# Define a function to returns the closest people based on  given proximity distance\n",
        "%%time\n",
        "def find_closest(dist,num,thresh):\n",
        "  p1 = []\n",
        "  p2 = []\n",
        "  d = []\n",
        "  for i in range(num):\n",
        "    for j in range(i, num):\n",
        "      if( (i!=j) & (dist[i][j] <= thresh)):\n",
        "        p1.append(i)\n",
        "        p2.append(j)\n",
        "        d.append(dist[i][j])\n",
        "  return p1, p2, d"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8W8jabZmPu9d"
      },
      "source": [
        "# Set the threshold for the proximity distance\n",
        "import pandas as pd\n",
        "\n",
        "thresh = 100\n",
        "p1, p2, d = find_closest(dist, num, thresh)\n",
        "df = pd.DataFrame({\"p1\":p1, \"p2\":p2, \"dist\":d})\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j2LruTZEPx2I"
      },
      "source": [
        "# Define a function to change the color of the closest people to red\n",
        "def change_2_red(img,person,p1,p2):\n",
        "  risky = np.unique(p1+p2)\n",
        "  for i in risky:\n",
        "    x1,y1,x2,y2 = person[i]\n",
        "    _ = cv2.rectangle(img, (x1, y1), (x2, y2), (255,0,0), 2)  \n",
        "  return img"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ddq7Xq6pP28k"
      },
      "source": [
        "# change the color of the closest people to red\n",
        "# call function\n",
        "img = change_2_red(img,person,p1,p2)\n",
        "\n",
        "plt.figure(figsize=(20,10))\n",
        "plt.imshow(img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DcbzEvK2P5hd"
      },
      "source": [
        "# Repeating above steps on each and every frame of the video\n",
        "import os\n",
        "import re\n",
        "\n",
        "names=os.listdir('frames/')\n",
        "names.sort(key=lambda f: int(re.sub('\\D', '', f)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5gPApMBoP_2t"
      },
      "source": [
        "# Define a function that performs all the steps we covered on each and every frame of the video\n",
        "\n",
        "def find_closest_people(name,thresh):\n",
        "\n",
        "  img = cv2.imread('frames/'+name)\n",
        "  outputs = predictor(img)\n",
        "  classes = outputs['instances'].pred_classes.cpu().numpy()\n",
        "  bbox = outputs['instances'].pred_boxes.tensor.cpu().numpy()\n",
        "  ind = np.where(classes==0)[0]\n",
        "  person = bbox[ind]\n",
        "  midpoints = [mid_point(img, person, i) for i in range(len(person))]\n",
        "  num = len(midpoints)\n",
        "  dist = compute_distance(midpoints,num)\n",
        "  p1, p2, d = find_closest(dist, num, thresh)\n",
        "  img = change_2_red(img, person, p1, p2)\n",
        "  cv2.imwrite('frames/'+name, img)\n",
        "  return 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M2jwTK7TQDJN"
      },
      "source": [
        "# Identify the closest people in each frame and change color to red\n",
        "from tqdm import tqdm\n",
        "thresh=100\n",
        "_ = [find_closest_people(names[i],thresh) for i in tqdm(range(len(names))) ]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2i83LhaZQFyM"
      },
      "source": [
        "# convert the frames back to a video.\n",
        "%%time\n",
        "frames = os.listdir('frames/')\n",
        "frames.sort(key=lambda f: int(re.sub('\\D', '', f)))\n",
        "\n",
        "frame_array=[]\n",
        "\n",
        "for i in range(len(frames)):\n",
        "    \n",
        "    #reading each files\n",
        "    img = cv2.imread('frames/'+frames[i])\n",
        "    img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    height, width, layers = img.shape\n",
        "    size = (width,height)\n",
        "    \n",
        "    #inserting the frames into an image array\n",
        "    frame_array.append(img)\n",
        "\n",
        "out = cv2.VideoWriter('sample_output.mp4',cv2.VideoWriter_fourcc(*'DIVX'), 25, size)\n",
        " \n",
        "for i in range(len(frame_array)):\n",
        "    # writing to a image array\n",
        "    out.write(frame_array[i])\n",
        "out.release()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}